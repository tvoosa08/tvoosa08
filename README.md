# 👋 Hi, I'm Teja Voosa

**Data Engineer | AWS & GCP Certified | AdTech & Big Data Specialist**

Hyderabad, Telangana, India  
[LinkedIn: linkedin.com/in/tejavoosa](https://linkedin.com/in/tejavoosa)  
Email: tejavoosa427@gmail.com / tvoosa@gmail.com

---

## 🚀 About Me

I'm a passionate Data Engineer with hands-on experience designing and building scalable, cost-efficient data pipelines for large-scale AdTech and media applications. At LTIMindtree, I build robust solutions using AWS, GCP, Python, PySpark, and Airflow, driving efficiency and innovation in cloud data workflows. I love tackling big data challenges, modernizing legacy systems, and optimizing cloud costs.

---

## 🛠️ Skills & Tools
<h3 align="left">Languages and Tools:</h3>
<p align="left"> <a href="https://aws.amazon.com" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="aws" width="40" height="40"/> </a> <a href="https://www.docker.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original-wordmark.svg" alt="docker" width="40" height="40"/> </a> <a href="https://cloud.google.com" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/google_cloud/google_cloud-icon.svg" alt="gcp" width="40" height="40"/> </a> <a href="https://git-scm.com/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> </a> <a href="https://hadoop.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hadoop/apache_hadoop-icon.svg" alt="hadoop" width="40" height="40"/> </a> <a href="https://hive.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_hive/apache_hive-icon.svg" alt="hive" width="40" height="40"/> </a> <a href="https://kafka.apache.org/" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/apache_kafka/apache_kafka-icon.svg" alt="kafka" width="40" height="40"/> </a> <a href="https://kubernetes.io" target="_blank" rel="noreferrer"> <img src="https://www.vectorlogo.zone/logos/kubernetes/kubernetes-icon.svg" alt="kubernetes" width="40" height="40"/> </a> <a href="https://www.linux.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" alt="linux" width="40" height="40"/> </a> <a href="https://www.microsoft.com/en-us/sql-server" target="_blank" rel="noreferrer"> <img src="https://www.svgrepo.com/show/303229/microsoft-sql-server-logo.svg" alt="mssql" width="40" height="40"/> </a> <a href="https://www.mysql.com/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg" alt="mysql" width="40" height="40"/> </a> <a href="https://www.postgresql.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/postgresql/postgresql-original-wordmark.svg" alt="postgresql" width="40" height="40"/> </a> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> </p>

- **Cloud:** AWS (Redshift, MWAA, Lambda, EMR, S3), GCP (BigQuery, Composer, Cloud Functions, Dataproc)
- **Data Engineering:** Airflow, ETL/ELT, Data Migration, Pipeline Optimization
- **Programming:** Python, PySpark, SQL
- **Other:** Hadoop, Data Quality, Performance Tuning, Cross-functional Collaboration

---

## 🏆 Certifications

- **Google Cloud Certified Professional Data Engineer** (Jun 2024 – Jul 2026)
- **Google Certified Associate Cloud Engineer** (Nov 2023 – Nov 2026)
- **AWS Certified Developer Associate** (Apr 2023 – Apr 2026)
- **AWS Certified Cloud Practitioner** (Jan 2023 – Jan 2026)

---

## 💼 Experience

**Data Engineer, LTIMindtree**  
Jan 2022 – Present | Hyderabad, India

- Developed scalable data pipelines using Airflow, AWS, and GCP for a leading AdTech client, boosting efficiency by 30%.
- Built robust ETL workflows for large, diverse datasets across BigQuery, AWS EMR, S3, and Hadoop.
- Led performance tuning and optimization, reducing processing time and cloud costs.
- Automated data quality, archiving, and deletion processes for improved accuracy and storage efficiency.
- Collaborated with data science and engineering teams to deploy solutions at scale.

---

## 🌟 Featured Projects

### AdTech Data Engineering & Data Science (Mar 2022 – Present)
**Tech:** Python, PySpark, SQL, Airflow, AWS, GCP

- Developed and optimized pipelines for CTV/OTT advertising, leveraging identity-matching tech for audience unification.
- Designed, monitored & optimized Airflow DAGs for high availability and cost efficiency across AWS and GCP.
- Built custom Airflow operators (e.g., automated table removal) saving ~$10K/day in cloud costs.
- Led cloud storage migration, unifying regions and slashing expenses.
- Contributed to next-gen Graph2 (IP & Device Graph) pipeline, replacing legacy systems.
- Automated dataset deletion across BQ, GCS, and S3 for major savings.
- Modernized workflows (Python 2→3, Linux to Airflow) for better scalability and cost.
- Partnered with Data Science on audience segmentation, targeting, and analytics enhancements.

---

## 📚 Education

**B.Sc. in Computer Science**  
Dr. B.R. Ambedkar University, Srikakulam  
Sep 2017 – May 2021

---

## 📫 Let's Connect!

- [LinkedIn](https://linkedin.com/in/tejavoosa)
- Email: tejavoosa427@gmail.com / tvoosa@gmail.com

---

<!--
⭐ Fun fact: I enjoy solving cloud cost puzzles and optimizing data workflows for scale and speed!
-->
